{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a94f9b50-0c74-4d9b-9498-7129ad00086e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import matplotlib.colors as mcolors\n",
    "import shutil\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from skimage.transform import resize\n",
    "from skimage.metrics import structural_similarity as ssim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "517b8bd8-0c1a-4067-b43d-0ce95a7059f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combinar_imagenes(imagenes_seleccionadas):\n",
    "    # Asegurarse de que tenemos al menos una imagen\n",
    "    if len(imagenes_seleccionadas) > 0:\n",
    "        # Convertir imagenes_seleccionadas a una matriz numpy\n",
    "        imagenes_seleccionadas = np.array(imagenes_seleccionadas)\n",
    "        \n",
    "        # Verificar que tengamos al menos 4 imágenes seleccionadas\n",
    "        if imagenes_seleccionadas.shape[0] >= 4:\n",
    "            # Crear un array para almacenar las imágenes reorganizadas\n",
    "            imagenes_reorganizadas = np.zeros((1440,1440), dtype=np.uint8)\n",
    "            \n",
    "            # Iterar sobre cada imagen y colocarla en su posición deseada\n",
    "            for i, img in enumerate(imagenes_seleccionadas[:4]):\n",
    "                if i == 0:  # Parte superior izquierda\n",
    "                    imagenes_reorganizadas[:720, :720] = img.astype(np.uint8)\n",
    "                elif i == 1:  # Parte superior derecha\n",
    "                    imagenes_reorganizadas[:720, 720:] = img.astype(np.uint8)\n",
    "                elif i == 2:  # Parte inferior izquierda\n",
    "                    imagenes_reorganizadas[720:, :720] = img.astype(np.uint8)\n",
    "                elif i == 3:  # Parte inferior derecha\n",
    "                    imagenes_reorganizadas[720:, 720:] = img.astype(np.uint8)\n",
    "    \n",
    "            return imagenes_reorganizadas\n",
    "        else:\n",
    "            print(\"Error: Se requieren al menos 4 imágenes seleccionadas.\")\n",
    "    else:\n",
    "        print(\"Error: No se han seleccionado imágenes.\")\n",
    "    print(imagenes_reorganizadas.shape)\n",
    "    \n",
    "# Ejemplo de uso\n",
    "# Suponiendo que tienes una lista de imágenes llamada imagenes_seleccionadas\n",
    "# Llamamos a la función con esta lista de imágenes\n",
    "# resultado = combinar_imagenes(imagenes_seleccionadas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8aacbf0-ac22-4511-84ac-e3ff69017a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seleccionar_imagenes(columna, filas_mismo_study_uid, pathNumpy, numImagenes):\n",
    "    # Inicializar las imágenes seleccionadas con imágenes en negro de tamaño 720x720\n",
    "    imagenes_seleccionadas = np.zeros((numImagenes, 4, 720, 720), dtype=np.uint8)\n",
    "    indice_imagen_cargada = 0\n",
    "    for i, row in filas_mismo_study_uid.iterrows():\n",
    "        view = row[\"View\"]\n",
    "        nombre = f\"{view}-{i}.npy\"\n",
    "        ruta = os.path.join(f\"{pathNumpy}/{columna}\", nombre)\n",
    "        ##print(ruta)\n",
    "        if os.path.exists(ruta):\n",
    "            imagen_cargada = np.load(ruta)\n",
    "            for j in range(numImagenes):\n",
    "                # Calcular el índice de la imagen en imagen_cargada\n",
    "                indice_imagen = j * (imagen_cargada.shape[0] // numImagenes)\n",
    "                \n",
    "                # Verificar si el índice es válido\n",
    "                if indice_imagen < imagen_cargada.shape[0]:\n",
    "                    if view == 'lcc':\n",
    "                        imagenes_seleccionadas[j, 0] = imagen_cargada[indice_imagen, :, :, 1]\n",
    "                    elif view == 'rcc':\n",
    "                        imagenes_seleccionadas[j, 1] = imagen_cargada[indice_imagen, :, :, 1]\n",
    "                    elif view == 'lmlo':\n",
    "                        imagenes_seleccionadas[j, 2] = imagen_cargada[indice_imagen, :, :, 1]\n",
    "                    elif view == 'rmlo':\n",
    "                        imagenes_seleccionadas[j, 3] = imagen_cargada[indice_imagen, :, :, 1]\n",
    "                \n",
    "    return imagenes_seleccionadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afc9dfcf-db7b-4203-8051-9b4ed6dda65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtener_columna(fila):\n",
    "    # Verificar el valor de cada columna y asignar el nombre correspondiente a las variables\n",
    "    columna = None\n",
    "    if fila[\"Normal\"] == 1:\n",
    "        columna = \"/Normal\"\n",
    "    elif fila[\"Actionable\"] == 1:\n",
    "        columna = \"/Actionable\"\n",
    "    elif fila[\"Benign\"] == 1:\n",
    "        columna = \"/Benign\"\n",
    "    elif fila[\"Cancer\"] == 1:\n",
    "        columna = \"/Cancer\"\n",
    "    return columna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb8dd0b-ee44-4421-a234-10f45ef4e9c5",
   "metadata": {},
   "source": [
    "# Comprobaciones iniciales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21ee2c0b-544e-447c-ad97-c3e5164c0938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El máximo número de repeticiones es: 4\n",
      "Número de filas con el máximo número de repeticiones: 400\n"
     ]
    }
   ],
   "source": [
    "pathdf = \"D:/TFG/Codigo/InfTest/merged_dfTest_serialized.pickle\"\n",
    "merged_df = pd.read_pickle(pathdf)\n",
    "# Luego, usa el método value_counts() para contar cuántas veces aparece cada valor en la columna 'StudyUID'\n",
    "counts = merged_df['StudyUID'].value_counts()\n",
    "\n",
    "# Ahora, encuentra el máximo número de repeticiones\n",
    "max_repeats = counts.max()\n",
    "\n",
    "# Finalmente, cuenta cuántas filas tienen este máximo número de repeticiones\n",
    "rows_with_max_repeats = counts[counts == max_repeats].shape[0]\n",
    "\n",
    "# Imprime el resultado\n",
    "print(\"El máximo número de repeticiones es:\", max_repeats)\n",
    "print(\"Número de filas con el máximo número de repeticiones:\", rows_with_max_repeats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92b86c01-439d-4231-a877-ee13ceaa72ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PatientID</th>\n",
       "      <th>StudyUID</th>\n",
       "      <th>View</th>\n",
       "      <th>descriptive_path</th>\n",
       "      <th>Normal</th>\n",
       "      <th>Actionable</th>\n",
       "      <th>Benign</th>\n",
       "      <th>Cancer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DBT-P00002</td>\n",
       "      <td>DBT-S03345</td>\n",
       "      <td>lcc</td>\n",
       "      <td>Breast-Cancer-Screening-DBT/DBT-P00002/01-01-2...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DBT-P00002</td>\n",
       "      <td>DBT-S03345</td>\n",
       "      <td>lmlo</td>\n",
       "      <td>Breast-Cancer-Screening-DBT/DBT-P00002/01-01-2...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DBT-P00002</td>\n",
       "      <td>DBT-S03345</td>\n",
       "      <td>rcc</td>\n",
       "      <td>Breast-Cancer-Screening-DBT/DBT-P00002/01-01-2...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DBT-P00002</td>\n",
       "      <td>DBT-S03345</td>\n",
       "      <td>rmlo</td>\n",
       "      <td>Breast-Cancer-Screening-DBT/DBT-P00002/01-01-2...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DBT-P00114</td>\n",
       "      <td>DBT-S03767</td>\n",
       "      <td>rmlo</td>\n",
       "      <td>Breast-Cancer-Screening-DBT/DBT-P00114/01-01-2...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1158</th>\n",
       "      <td>DBT-P02242</td>\n",
       "      <td>DBT-S01269</td>\n",
       "      <td>rmlo</td>\n",
       "      <td>Breast-Cancer-Screening-DBT/DBT-P02242/01-01-2...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1159</th>\n",
       "      <td>DBT-P02545</td>\n",
       "      <td>DBT-S04030</td>\n",
       "      <td>lcc</td>\n",
       "      <td>Breast-Cancer-Screening-DBT/DBT-P02545/01-01-2...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1160</th>\n",
       "      <td>DBT-P02545</td>\n",
       "      <td>DBT-S04030</td>\n",
       "      <td>lmlo</td>\n",
       "      <td>Breast-Cancer-Screening-DBT/DBT-P02545/01-01-2...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1161</th>\n",
       "      <td>DBT-P02545</td>\n",
       "      <td>DBT-S04030</td>\n",
       "      <td>rcc</td>\n",
       "      <td>Breast-Cancer-Screening-DBT/DBT-P02545/01-01-2...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1162</th>\n",
       "      <td>DBT-P02545</td>\n",
       "      <td>DBT-S04030</td>\n",
       "      <td>rmlo</td>\n",
       "      <td>Breast-Cancer-Screening-DBT/DBT-P02545/01-01-2...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1163 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       PatientID    StudyUID  View  \\\n",
       "0     DBT-P00002  DBT-S03345   lcc   \n",
       "1     DBT-P00002  DBT-S03345  lmlo   \n",
       "2     DBT-P00002  DBT-S03345   rcc   \n",
       "3     DBT-P00002  DBT-S03345  rmlo   \n",
       "4     DBT-P00114  DBT-S03767  rmlo   \n",
       "...          ...         ...   ...   \n",
       "1158  DBT-P02242  DBT-S01269  rmlo   \n",
       "1159  DBT-P02545  DBT-S04030   lcc   \n",
       "1160  DBT-P02545  DBT-S04030  lmlo   \n",
       "1161  DBT-P02545  DBT-S04030   rcc   \n",
       "1162  DBT-P02545  DBT-S04030  rmlo   \n",
       "\n",
       "                                       descriptive_path  Normal  Actionable  \\\n",
       "0     Breast-Cancer-Screening-DBT/DBT-P00002/01-01-2...       1           0   \n",
       "1     Breast-Cancer-Screening-DBT/DBT-P00002/01-01-2...       1           0   \n",
       "2     Breast-Cancer-Screening-DBT/DBT-P00002/01-01-2...       1           0   \n",
       "3     Breast-Cancer-Screening-DBT/DBT-P00002/01-01-2...       1           0   \n",
       "4     Breast-Cancer-Screening-DBT/DBT-P00114/01-01-2...       0           0   \n",
       "...                                                 ...     ...         ...   \n",
       "1158  Breast-Cancer-Screening-DBT/DBT-P02242/01-01-2...       1           0   \n",
       "1159  Breast-Cancer-Screening-DBT/DBT-P02545/01-01-2...       1           0   \n",
       "1160  Breast-Cancer-Screening-DBT/DBT-P02545/01-01-2...       1           0   \n",
       "1161  Breast-Cancer-Screening-DBT/DBT-P02545/01-01-2...       1           0   \n",
       "1162  Breast-Cancer-Screening-DBT/DBT-P02545/01-01-2...       1           0   \n",
       "\n",
       "      Benign  Cancer  \n",
       "0          0       0  \n",
       "1          0       0  \n",
       "2          0       0  \n",
       "3          0       0  \n",
       "4          0       1  \n",
       "...      ...     ...  \n",
       "1158       0       0  \n",
       "1159       0       0  \n",
       "1160       0       0  \n",
       "1161       0       0  \n",
       "1162       0       0  \n",
       "\n",
       "[1163 rows x 8 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "657a953e-4e13-4dee-a255-787d222f8c38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de duplicados que cambian: 0\n"
     ]
    }
   ],
   "source": [
    "pathdf = \"D:/TFG/Codigo/InfTest/merged_dfTest_serialized.pickle\"\n",
    "merged_df = pd.read_pickle(pathdf)\n",
    "# Encuentra las filas duplicadas en función de la columna 'StudyUID'\n",
    "duplicated_study_uids = merged_df[merged_df.duplicated(subset=['StudyUID'], keep=False)]['StudyUID'].unique()\n",
    "\n",
    "# Contador para el número de duplicados que cambian\n",
    "changed_duplicates_count = 0\n",
    "\n",
    "# Itera sobre los StudyUID duplicados\n",
    "for study_uid in duplicated_study_uids:\n",
    "    study_uid_rows = merged_df[merged_df['StudyUID'] == study_uid]\n",
    "    previous_row = None\n",
    "    for index, row in study_uid_rows.iterrows():\n",
    "        if previous_row is not None:\n",
    "            if (row['Normal'] != previous_row['Normal'] or\n",
    "                row['Cancer'] != previous_row['Cancer'] or\n",
    "                row['Benign'] != previous_row['Benign'] or\n",
    "                row['Actionable'] != previous_row['Actionable']):\n",
    "                print(f\"Valores cambian en la fila con StudyUID {study_uid}:\")\n",
    "                display(pd.concat([previous_row, row], axis=1).T)\n",
    "                changed_duplicates_count += 1\n",
    "        previous_row = row\n",
    "\n",
    "# Mostrar el número de duplicados que cambian\n",
    "print(f\"Número de duplicados que cambian: {changed_duplicates_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "296063ee-7a66-4907-94c8-beb0b9ec4970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal\n",
      "1    928\n",
      "0    235\n",
      "Name: count, dtype: int64\n",
      "Actionable\n",
      "0    1003\n",
      "1     160\n",
      "Name: count, dtype: int64\n",
      "Benign\n",
      "0    1125\n",
      "1      38\n",
      "Name: count, dtype: int64\n",
      "Cancer\n",
      "0    1126\n",
      "1      37\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "pathdf = \"D:/TFG/Codigo/InfValidation/merged_dfValidation_serialized.pickle\"\n",
    "# Cargar el DataFrame desde un archivo pickle serializado\n",
    "merged_df = pd.read_pickle(pathdf)\n",
    "conteo_Normal = merged_df[\"Normal\"].value_counts()\n",
    "conteo_Actionable = merged_df[\"Actionable\"].value_counts()\n",
    "conteo_Benign = merged_df[\"Benign\"].value_counts()\n",
    "conteo_Cancer = merged_df[\"Cancer\"].value_counts()\n",
    "\n",
    "# Mostrar los distintos valores y sus conteos\n",
    "print(conteo_Normal)\n",
    "print(conteo_Actionable)\n",
    "print(conteo_Benign)\n",
    "print(conteo_Cancer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32447966-635c-4899-852b-99691572df0a",
   "metadata": {},
   "source": [
    "# 4 imagenes en 1:\n",
    "## Validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a67db0ab-a800-4685-86fe-f2c64468decf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando imagen: 100%|███████████████████████████████████████████████████████████| 1163/1163 [09:09<00:00,  2.12it/s]\n"
     ]
    }
   ],
   "source": [
    "# Validation\n",
    "pathdf = \"D:/Codigo/Datos/InfValidation/merged_dfValidation_serialized.pickle\"\n",
    "pathNumpySave = \"E:/NumpysTotal\"\n",
    "pathNumpy = \"D:/Numpys/imagenesValCompletas\"\n",
    "\n",
    "# Cargar el DataFrame desde un archivo pickle serializado\n",
    "merged_df = pd.read_pickle(pathdf)\n",
    "\n",
    "# Tamaño cuadrado deseado para las imágenes (en píxeles)\n",
    "tamano_cuadrado = 96\n",
    "\n",
    "# Iterar sobre las filas del DataFrame merged_df\n",
    "for index, row in tqdm(merged_df.iterrows(), total=merged_df.shape[0], desc=\"Cargando imagen\"):\n",
    "    filas_mismo_study_uid = merged_df[merged_df['StudyUID'] == row['StudyUID']]\n",
    "    \n",
    "    if not filas_mismo_study_uid.empty:\n",
    "        merged_df.drop(filas_mismo_study_uid.index, inplace=True)\n",
    "        \n",
    "        # Inicializa la imagen final como una matriz de ceros\n",
    "        final_image = np.zeros((1440, 1440), dtype=np.uint8)\n",
    "        \n",
    "        # Obtener la columna correspondiente Normal, Actionable, Cancer o Benign\n",
    "        columna = obtener_columna(filas_mismo_study_uid.iloc[0])\n",
    "        numImagenes = 10\n",
    "        # Seleccionar las imágenes correspondientes a esta fila\n",
    "        imagenes_seleccionadas = seleccionar_imagenes(columna, filas_mismo_study_uid, pathNumpy, numImagenes)\n",
    "        \n",
    "        # Crear una lista para almacenar los resultados\n",
    "        resultados = []\n",
    "        for i in range(len(imagenes_seleccionadas)):\n",
    "            resultado = combinar_imagenes(imagenes_seleccionadas[i])\n",
    "            resultados.append(resultado)\n",
    "        \n",
    "        # Convertir la lista de resultados en un numpy array\n",
    "        resultados_array = np.array(resultados)\n",
    "        \n",
    "        # Guardar el numpy array\n",
    "        nombre = f\"{filas_mismo_study_uid.iloc[0]['StudyUID']}_{filas_mismo_study_uid.iloc[0]['PatientID']}\"\n",
    "        \n",
    "        ruta_archivo = os.path.join(f\"{pathNumpySave}/{columna}\", nombre)\n",
    "        if os.path.exists(ruta_archivo):\n",
    "            print(f\"El archivo {ruta_archivo} ya existe.\")\n",
    "        \n",
    "        np.save(ruta_archivo, resultados_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a902bd-a45e-4b56-81f6-1d101547a29c",
   "metadata": {},
   "source": [
    "## Test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5628a654-7f2e-4949-b3f0-a6f3122251e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando imagen: 100%|███████████████████████████████████████████████████████████| 1721/1721 [14:02<00:00,  2.04it/s]\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "pathdf = \"D:/Codigo/Datos/InfTest/merged_dfTest_serialized.pickle\"\n",
    "pathNumpySave = \"E:/NumpysTotal\"\n",
    "pathNumpy = \"D:/Numpys/imagenesTestCompletas\"\n",
    "\n",
    "num_max = 37\n",
    "num_normal = 0\n",
    "num_actionable = 0\n",
    "num_benign = 0\n",
    "num_cancer = 0\n",
    "\n",
    "# Cargar el DataFrame desde un archivo pickle serializado\n",
    "merged_df = pd.read_pickle(pathdf)\n",
    "\n",
    "# Tamaño cuadrado deseado para las imágenes (en píxeles)\n",
    "tamano_cuadrado = 96\n",
    "\n",
    "# Iterar sobre las filas del DataFrame merged_df\n",
    "for index, row in tqdm(merged_df.iterrows(), total=merged_df.shape[0], desc=\"Cargando imagen\"):\n",
    "    filas_mismo_study_uid = merged_df[merged_df['StudyUID'] == row['StudyUID']]\n",
    "    \n",
    "    if not filas_mismo_study_uid.empty:\n",
    "        merged_df.drop(filas_mismo_study_uid.index, inplace=True)\n",
    "        \n",
    "        # Inicializa la imagen final como una matriz de ceros\n",
    "        final_image = np.zeros((1440, 1440), dtype=np.uint8)\n",
    "        \n",
    "        # Obtener la columna correspondiente Normal, Actionable, Cancer o Benign\n",
    "        columna = obtener_columna(filas_mismo_study_uid.iloc[0])\n",
    "        numImagenes = 10\n",
    "        # Seleccionar las imágenes correspondientes a esta fila\n",
    "        imagenes_seleccionadas = seleccionar_imagenes(columna, filas_mismo_study_uid, pathNumpy, numImagenes)\n",
    "        \n",
    "        # Crear una lista para almacenar los resultados\n",
    "        resultados = []\n",
    "        for i in range(len(imagenes_seleccionadas)):\n",
    "            resultado = combinar_imagenes(imagenes_seleccionadas[i])\n",
    "            resultados.append(resultado)\n",
    "        \n",
    "        # Convertir la lista de resultados en un numpy array\n",
    "        resultados_array = np.array(resultados)\n",
    "        \n",
    "        # Guardar el numpy array\n",
    "        nombre = f\"{filas_mismo_study_uid.iloc[0]['StudyUID']}_{filas_mismo_study_uid.iloc[0]['PatientID']}\"\n",
    "        \n",
    "        ruta_archivo = os.path.join(f\"{pathNumpySave}/{columna}\", nombre)\n",
    "        if os.path.exists(ruta_archivo):\n",
    "            print(f\"El archivo {ruta_archivo} ya existe.\")\n",
    "        \n",
    "        np.save(ruta_archivo, resultados_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c1dbf8-aa69-44d9-ab72-2b896352d027",
   "metadata": {},
   "source": [
    "## Training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa6e2fd1-50e5-43fb-ba61-0494c5dd7132",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cargando imagen: 100%|█████████████████████████████████████████████████████████| 19148/19148 [46:12<00:00,  6.91it/s]\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "pathdf = \"D:/Codigo/Datos/InfTraining/merged_dfTraining_serialized.pickle\"\n",
    "pathNumpySave = \"E:/NumpysTotal\"\n",
    "pathNumpy = \"D:/Numpys/ImagenesTrainingCompletas\"\n",
    "\n",
    "# Cargar el DataFrame desde un archivo pickle serializado\n",
    "merged_df = pd.read_pickle(pathdf)\n",
    "\n",
    "# Tamaño cuadrado deseado para las imágenes (en píxeles)\n",
    "tamano_cuadrado = 96\n",
    "\n",
    "# Iterar sobre las filas del DataFrame merged_df\n",
    "for index, row in tqdm(merged_df.iterrows(), total=merged_df.shape[0], desc=\"Cargando imagen\"):\n",
    "    filas_mismo_study_uid = merged_df[merged_df['StudyUID'] == row['StudyUID']]\n",
    "    if index > 13331:\n",
    "        ##print(row)\n",
    "        if not filas_mismo_study_uid.empty:\n",
    "            merged_df.drop(filas_mismo_study_uid.index, inplace=True)\n",
    "            \n",
    "            # Inicializa la imagen final como una matriz de ceros\n",
    "            final_image = np.zeros((1440, 1440), dtype=np.uint8)\n",
    "            \n",
    "            # Obtener la columna correspondiente Normal, Actionable, Cancer o Benign\n",
    "            columna = obtener_columna(filas_mismo_study_uid.iloc[0])\n",
    "            if columna != \"Normal\":\n",
    "                numImagenes = 10\n",
    "                # Seleccionar las imágenes correspondientes a esta fila\n",
    "                imagenes_seleccionadas = seleccionar_imagenes(columna, filas_mismo_study_uid, pathNumpy, numImagenes)\n",
    "                \n",
    "                # Crear una lista para almacenar los resultados\n",
    "                resultados = []\n",
    "                for i in range(len(imagenes_seleccionadas)):\n",
    "                    resultado = combinar_imagenes(imagenes_seleccionadas[i])\n",
    "                    resultados.append(resultado)\n",
    "                \n",
    "                # Convertir la lista de resultados en un numpy array\n",
    "                resultados_array = np.array(resultados)\n",
    "                \n",
    "                # Guardar el numpy array\n",
    "                nombre = f\"{filas_mismo_study_uid.iloc[0]['StudyUID']}_{filas_mismo_study_uid.iloc[0]['PatientID']}\"\n",
    "                \n",
    "                ruta_archivo = os.path.join(f\"{pathNumpySave}/{columna}\", nombre)\n",
    "                if os.path.exists(ruta_archivo):\n",
    "                    print(f\"El archivo {ruta_archivo} ya existe.\")\n",
    "                \n",
    "                np.save(ruta_archivo, resultados_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea56a33-be80-45c6-ba27-f0a1c8cda4d6",
   "metadata": {},
   "source": [
    "# -------------------------------------- Pruebas -----------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcbe99c3-245a-4b3b-a094-13b66b336e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      PatientID    StudyUID  View  \\\n",
      "297  DBT-P03694  DBT-S00795   lcc   \n",
      "298  DBT-P03694  DBT-S00795  lmlo   \n",
      "299  DBT-P03694  DBT-S00795   rcc   \n",
      "300  DBT-P03694  DBT-S00795  rmlo   \n",
      "\n",
      "                                      descriptive_path  Normal  Actionable  \\\n",
      "297  Breast-Cancer-Screening-DBT/DBT-P03694/01-01-2...       0           1   \n",
      "298  Breast-Cancer-Screening-DBT/DBT-P03694/01-01-2...       0           1   \n",
      "299  Breast-Cancer-Screening-DBT/DBT-P03694/01-01-2...       0           1   \n",
      "300  Breast-Cancer-Screening-DBT/DBT-P03694/01-01-2...       0           1   \n",
      "\n",
      "     Benign  Cancer  \n",
      "297       0       0  \n",
      "298       0       0  \n",
      "299       0       0  \n",
      "300       0       0  \n",
      "imagenes_seleccionadas: (10, 4, 720, 720)\n",
      "(10, 1440, 1440)\n"
     ]
    }
   ],
   "source": [
    "#Prueba construccion imagen\n",
    "pathdf = \"D:/Codigo/Datos/InfValidation/merged_dfValidation_serialized.pickle\"\n",
    "pathNumpy = \"D:/TFG/Numpys/imagenesValCompletas\"\n",
    "merged_df = pd.read_pickle(pathdf)\n",
    "index = 300\n",
    "primera_fila = merged_df.iloc[index]  #301 tiene una imagen\n",
    "\n",
    "# Encuentra todas las filas con el mismo 'StudyUID' que la primera fila\n",
    "filas_mismo_study_uid = merged_df[merged_df['StudyUID'] == primera_fila['StudyUID']]\n",
    "\n",
    "print(filas_mismo_study_uid)\n",
    "# Inicializa la imagen final como una matriz de ceros\n",
    "final_image = np.zeros((1440, 1440), dtype=np.uint8)\n",
    "\n",
    "# Obtener la columna correspondiente Normal, Actionable, Cancer o Benign\n",
    "columna = obtener_columna(filas_mismo_study_uid.iloc[0])\n",
    "numImagenes = 10\n",
    "# Seleccionar las imágenes correspondientes a esta fila\n",
    "imagenes_seleccionadas = seleccionar_imagenes(columna, filas_mismo_study_uid, pathNumpy, numImagenes)\n",
    "print(f\"imagenes_seleccionadas: {imagenes_seleccionadas.shape}\")\n",
    "\n",
    "# Crear una lista para almacenar los resultados\n",
    "resultados = []\n",
    "for i in range(len(imagenes_seleccionadas)):\n",
    "    resultado = combinar_imagenes(imagenes_seleccionadas[i])\n",
    "    resultados.append(resultado)\n",
    "\n",
    "# Convertir la lista de resultados en un numpy array\n",
    "resultados_array = np.array(resultados)\n",
    "\n",
    "# Verificar las formas de los resultados\n",
    "print(resultados_array.shape)\n",
    "\n",
    "# # Guardar el numpy array\n",
    "np.save(\"resultados.npy\", resultados_array)\n",
    "\n",
    "\n",
    "# for i in range(10):\n",
    "#     resultado = combinar_imagenes(imagenes_seleccionadas[i])\n",
    "#     print(resultado.shape)# Guarda la imagen final\n",
    "#     cv2.imwrite(f\"resultados/image_{i}.png\", resultado)\n",
    "#     # Guardar la imagen final como un archivo Numpy serializado\n",
    "    #np.save(f\"final_image_{index}.npy\", resultado)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "59874b15-9acc-4d54-9319-ba5f013b711c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores distintos en la columna 'View' y su frecuencia:\n",
      "Valor: lcc, Frecuencia: 292\n",
      "Valor: lmlo, Frecuencia: 291\n",
      "Valor: rmlo, Frecuencia: 290\n",
      "Valor: rcc, Frecuencia: 287\n",
      "Valor: lmlo1, Frecuencia: 2\n",
      "Valor: lcc1, Frecuencia: 1\n",
      "Filas correspondientes a los valores extraños:\n",
      "      PatientID    StudyUID   View  \\\n",
      "80   DBT-P01207  DBT-S03000   lcc1   \n",
      "81   DBT-P01207  DBT-S03000  lmlo1   \n",
      "323  DBT-P04097  DBT-S02552  lmlo1   \n",
      "\n",
      "                                      descriptive_path  Normal  Actionable  \\\n",
      "80   Breast-Cancer-Screening-DBT/DBT-P01207/01-01-2...       0           0   \n",
      "81   Breast-Cancer-Screening-DBT/DBT-P01207/01-01-2...       0           0   \n",
      "323  Breast-Cancer-Screening-DBT/DBT-P04097/01-01-2...       0           0   \n",
      "\n",
      "     Benign  Cancer  \n",
      "80        0       1  \n",
      "81        0       1  \n",
      "323       1       0  \n",
      "Filas correspondientes al estudio 'DBT-S02552':\n",
      "      PatientID    StudyUID   View  \\\n",
      "322  DBT-P04097  DBT-S02552   lmlo   \n",
      "323  DBT-P04097  DBT-S02552  lmlo1   \n",
      "\n",
      "                                      descriptive_path  Normal  Actionable  \\\n",
      "322  Breast-Cancer-Screening-DBT/DBT-P04097/01-01-2...       0           0   \n",
      "323  Breast-Cancer-Screening-DBT/DBT-P04097/01-01-2...       0           0   \n",
      "\n",
      "     Benign  Cancer  \n",
      "322       1       0  \n",
      "323       1       0  \n",
      "Forma de la imagen seleccionada: (720, 720)\n",
      "Forma de la imagen seleccionada: (720, 720)\n"
     ]
    }
   ],
   "source": [
    "#Prueba construccion imagen\n",
    "pathdf = \"D:/TFG/Codigo/InfValidation/merged_dfValidation_serialized.pickle\"\n",
    "pathNumpy = \"D:/TFG/Numpys/imagenesValCompletas\"\n",
    "# Cargar el DataFrame desde un archivo pickle serializado\n",
    "merged_df = pd.read_pickle(pathdf)\n",
    "# Tamaño cuadrado deseado para las imágenes (en píxeles)\n",
    "tamano_cuadrado = 96\n",
    "\n",
    "# Contar la frecuencia de cada valor en la columna \"View\"\n",
    "frecuencia_valores = merged_df[\"View\"].value_counts()\n",
    "\n",
    "# Mostrar los valores distintos y su frecuencia\n",
    "print(\"Valores distintos en la columna 'View' y su frecuencia:\")\n",
    "for valor, frecuencia in frecuencia_valores.items():\n",
    "    print(f\"Valor: {valor}, Frecuencia: {frecuencia}\")\n",
    "\n",
    "# Definir los valores extraños\n",
    "valores_extraños = [\"lmlo1\", \"lcc1\"]\n",
    "\n",
    "# Filtrar el DataFrame para obtener las filas correspondientes a los valores extraños\n",
    "filas_extrañas = merged_df[merged_df[\"View\"].isin(valores_extraños)]\n",
    "\n",
    "# Mostrar las filas correspondientes a los valores extraños\n",
    "print(\"Filas correspondientes a los valores extraños:\")\n",
    "print(filas_extrañas)\n",
    "\n",
    "# Filtrar el DataFrame para obtener las filas con el valor 'DBT-S02552' en la columna 'StudyUID'\n",
    "filas_estudio_especifico = merged_df[merged_df[\"StudyUID\"] == 'DBT-S02552']\n",
    "\n",
    "# Mostrar las filas correspondientes al estudio específico\n",
    "print(\"Filas correspondientes al estudio 'DBT-S02552':\")\n",
    "print(filas_estudio_especifico)\n",
    "\n",
    "%matplotlib qt\n",
    "\n",
    "for index, row in filas_estudio_especifico.iterrows():\n",
    "    view = row[\"View\"]\n",
    "    nombre = f\"{view}-{index}.npy\"\n",
    "    ruta = os.path.join(f\"{pathNumpy}/Benign\", nombre)\n",
    "    if os.path.exists(ruta):\n",
    "        imagen_cargada = np.load(ruta)\n",
    "        # Seleccionar la imagen en la posición 30\n",
    "        imagen_seleccionada = imagen_cargada[30]\n",
    "        # Ajustar la forma de la imagen\n",
    "        imagen_seleccionada = np.squeeze(imagen_seleccionada)\n",
    "        # Reducir la forma a (720, 720)\n",
    "        imagen_seleccionada = imagen_seleccionada[:, :, 1]  # Tomar solo un canal\n",
    "        # Verificar la forma de los datos de la imagen\n",
    "        print(f\"Forma de la imagen seleccionada: {imagen_seleccionada.shape}\")\n",
    "        \n",
    "        # Normalizar los valores de píxeles\n",
    "        imagen_normalizada = imagen_seleccionada / np.max(imagen_seleccionada)\n",
    "        \n",
    "        # Mostrar la imagen en una nueva ventana flotante\n",
    "        plt.figure()\n",
    "        plt.imshow(imagen_normalizada, cmap='gray')  # Usar escala de grises\n",
    "        plt.axis('off')  # Ocultar los ejes\n",
    "        plt.title(f'Imagen {nombre} - Posición 30')  # Agregar título con el nombre de la imagen\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(f\"No se encontró el archivo: {ruta}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cdd7a7-0fcd-4f0d-9ca3-242ef19b8ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primer calculo MUY LENTO MUCHOS DIAS\n",
    "# Normal\n",
    "pathNumpy = \"E:/NumpysTotal/Normal/\"\n",
    "pathNumpySave = \"E:/NumpysSeleccionadas/Normal\"\n",
    "NumImagenes = 89  # Img Cancer Validation dataset\n",
    "\n",
    "# Lista para almacenar las rutas de los archivos .npy\n",
    "rutas_archivos = []\n",
    "for filename in os.listdir(pathNumpy):\n",
    "    if filename.endswith(\".npy\"):\n",
    "        rutas_archivos.append(os.path.join(pathNumpy, filename))\n",
    "\n",
    "# Mostrar la cantidad de archivos en rutas_archivos\n",
    "print(\"Cantidad de archivos .npy encontrados:\", len(rutas_archivos))\n",
    "\n",
    "archivo_progreso = \"progresoSeleccionNormal.npy\"\n",
    "# Comprobar si existe un archivo de progreso guardado\n",
    "if os.path.exists(archivo_progreso):\n",
    "    print(\"Cargando progreso previo...\")\n",
    "    ssim_scores_promedio = np.load(archivo_progreso)\n",
    "else:\n",
    "    ssim_scores_promedio = np.empty((0,))\n",
    "\n",
    "# Calcular SSIM entre cada archivo y todos los demás archivos\n",
    "for i, ruta_i in enumerate(rutas_archivos):\n",
    "    if i >= len(ssim_scores_promedio):  # Continuar desde donde se quedó\n",
    "        archivo_i = np.load(ruta_i)\n",
    "        scores_i = []\n",
    "        for j, ruta_j in enumerate(rutas_archivos):\n",
    "            if i != j:  # Evitar comparar un archivo consigo mismo\n",
    "                archivo_j = np.load(ruta_j)\n",
    "                score_sum = 0\n",
    "                for k in range(10):  # Calcular SSIM para cada par de imágenes dentro de los archivos\n",
    "                    score, _ = ssim(archivo_i[k], archivo_j[k], full=True)\n",
    "                    score_sum += score\n",
    "                print(f\"Calculando: {i} - {j}  Total: {len(rutas_archivos)}\", end='\\r') \n",
    "                avg_score = score_sum / 10  # Promedio de las puntuaciones SSIM para las 10 imágenes\n",
    "                scores_i.append(avg_score)\n",
    "        ssim_scores_promedio.append((i, np.mean(scores_i)))\n",
    "        np.save(archivo_progreso, ssim_scores_promedio)\n",
    "\n",
    "# Ordenar los scores promedio de menor a mayor\n",
    "ssim_scores_promedio.sort(key=lambda x: x[1])\n",
    "\n",
    "# Seleccionar los NumImagenes archivos menos similares al resto\n",
    "indices_seleccionados = [idx for idx, _ in ssim_scores_promedio[:NumImagenes]]\n",
    "\n",
    "# Guardar los archivos seleccionados con sus nombres originales\n",
    "for idx in indices_seleccionados:\n",
    "    nombre_original = os.path.basename(rutas_archivos[idx])  # Obtener el nombre original del archivo\n",
    "    np.save(os.path.join(pathNumpySave, nombre_original), np.load(rutas_archivos[idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6dfd258-d05c-48fd-874d-3ba218b0d60c",
   "metadata": {},
   "source": [
    "# ------------------------------ Comparar y seleccionar imágenes --------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e78a6cb-a59f-4d9f-88de-0308907accf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para calcular la Diferencia Absoluta (MAE) entre dos imágenes\n",
    "def calculate_mae(image1, image2):\n",
    "    return np.mean(np.abs(image1 - image2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aff6057-a99f-429b-a1e5-f3763769e18e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de archivos .npy encontrados: 5129\n",
      "Cantidad de archivos .npy seleccionados: 1282\n",
      "Cargando progreso previo...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Comparando imágenes:  42%|██████████████████▉                          | 540/1282 [13:01:45<18:07:42, 87.95s/archivo]"
     ]
    }
   ],
   "source": [
    "# Normal\n",
    "pathNumpy = \"E:/NumpysTotal/Normal/\"\n",
    "pathNumpySave = \"E:/NumpysSeleccionadas/Normal\"\n",
    "# Obtener el 25% de las imágenes (aproximadamente)\n",
    "rutas_archivos = []\n",
    "for filename in os.listdir(pathNumpy):\n",
    "    if filename.endswith(\".npy\"):\n",
    "        rutas_archivos.append(os.path.join(pathNumpy, filename))\n",
    "\n",
    "# Lista para almacenar las rutas de los archivos .npy\n",
    "print(\"Cantidad de archivos .npy encontrados:\", len(rutas_archivos))\n",
    "\n",
    "# Aleatoriamente seleccionar el 25% de las imágenes\n",
    "np.random.shuffle(rutas_archivos)\n",
    "rutas_archivos = rutas_archivos[:int(len(rutas_archivos) * 0.25)]\n",
    "\n",
    "print(\"Cantidad de archivos .npy seleccionados:\", len(rutas_archivos))\n",
    "\n",
    "# Comprobar si existe un archivo de progreso guardado\n",
    "archivo_progreso = \"progresoSeleccionNormal.npy\"\n",
    "if os.path.exists(archivo_progreso):\n",
    "    print(\"Cargando progreso previo...\")\n",
    "    ssim_scores_promedio = np.load(archivo_progreso)\n",
    "else:\n",
    "    ssim_scores_promedio = np.empty((0,))\n",
    "\n",
    "# Calcular la Diferencia Absoluta (MAE) entre cada par de imágenes si no se ha calculado previamente\n",
    "for i, ruta_i in enumerate(tqdm(rutas_archivos, desc=\"Comparando imágenes\", unit=\"archivo\", leave=False)):\n",
    "    if i >= len(ssim_scores_promedio):  # Continuar desde donde se quedó\n",
    "        archivo_i = np.load(ruta_i)\n",
    "        scores_i = []\n",
    "        for j, ruta_j in enumerate(rutas_archivos):\n",
    "            if i != j:  # Evitar comparar un archivo consigo mismo\n",
    "                archivo_j = np.load(ruta_j)\n",
    "                score = calculate_mae(archivo_i, archivo_j)\n",
    "                scores_i.append(score)\n",
    "        ssim_scores_promedio = np.append(ssim_scores_promedio, np.mean(scores_i))\n",
    "        \n",
    "        # Guardar el progreso cada cierto intervalo de tiempo\n",
    "        if i % 100 == 0:\n",
    "            np.save(archivo_progreso, ssim_scores_promedio)\n",
    "\n",
    "# Ordenar los scores promedio de menor a mayor\n",
    "sorted_indices = np.argsort(ssim_scores_promedio)\n",
    "\n",
    "# Seleccionar los NumImagenes archivos menos similares al resto\n",
    "indices_seleccionados = sorted_indices[:NumImagenes]\n",
    "\n",
    "# Guardar los archivos seleccionados con sus nombres originales\n",
    "for idx in indices_seleccionados:\n",
    "    nombre_original = os.path.basename(rutas_archivos[idx])  # Obtener el nombre original del archivo\n",
    "    np.save(os.path.join(pathNumpySave, nombre_original), np.load(rutas_archivos[idx]))\n",
    "\n",
    "# Guardar los resultados de los cálculos de MAE\n",
    "np.save(archivo_progreso, ssim_scores_promedio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fbfb9d-23a5-4629-b2ca-013cb463b012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benign\n",
    "pathNumpy = \"E:/NumpysTotal/Benign/\"\n",
    "pathNumpySave = \"E:/NumpysSeleccionadas/Benign\"\n",
    "NumImagenes = 89  # Img Cancer Validation dataset\n",
    "\n",
    "# Lista para almacenar las rutas de los archivos .npy\n",
    "rutas_archivos = []\n",
    "for filename in os.listdir(pathNumpy):\n",
    "    if filename.endswith(\".npy\"):\n",
    "        rutas_archivos.append(os.path.join(pathNumpy, filename))\n",
    "\n",
    "# Mostrar la cantidad de archivos en rutas_archivos\n",
    "print(\"Cantidad de archivos .npy encontrados:\", len(rutas_archivos))\n",
    "\n",
    "archivo_progreso = \"progresoSeleccionBenign.npy\"\n",
    "# Comprobar si existe un archivo de progreso guardado\n",
    "if os.path.exists(archivo_progreso):\n",
    "    print(\"Cargando progreso previo...\")\n",
    "    ssim_scores_promedio = np.load(archivo_progreso)\n",
    "else:\n",
    "    ssim_scores_promedio = np.empty((0,))\n",
    "\n",
    "# Calcular SSIM entre cada archivo y todos los demás archivos\n",
    "for i, ruta_i in enumerate(rutas_archivos):\n",
    "    if i >= len(ssim_scores_promedio):  # Continuar desde donde se quedó\n",
    "        archivo_i = np.load(ruta_i)\n",
    "        scores_i = []\n",
    "        for j, ruta_j in enumerate(rutas_archivos):\n",
    "            if i != j:  # Evitar comparar un archivo consigo mismo\n",
    "                archivo_j = np.load(ruta_j)\n",
    "                score_sum = 0\n",
    "                for k in range(10):  # Calcular SSIM para cada par de imágenes dentro de los archivos\n",
    "                    score, _ = ssim(archivo_i[k], archivo_j[k], full=True)\n",
    "                    score_sum += score\n",
    "                print(f\"Calculando: {i} - {j}  Total: {len(rutas_archivos)}\", end='\\r') \n",
    "                avg_score = score_sum / 10  # Promedio de las puntuaciones SSIM para las 10 imágenes\n",
    "                scores_i.append(avg_score)\n",
    "        ssim_scores_promedio.append((i, np.mean(scores_i)))\n",
    "        np.save(archivo_progreso, ssim_scores_promedio)\n",
    "\n",
    "# Ordenar los scores promedio de menor a mayor\n",
    "ssim_scores_promedio.sort(key=lambda x: x[1])\n",
    "\n",
    "# Seleccionar los NumImagenes archivos menos similares al resto\n",
    "indices_seleccionados = [idx for idx, _ in ssim_scores_promedio[:NumImagenes]]\n",
    "\n",
    "# Guardar los archivos seleccionados con sus nombres originales\n",
    "for idx in indices_seleccionados:\n",
    "    nombre_original = os.path.basename(rutas_archivos[idx])  # Obtener el nombre original del archivo\n",
    "    np.save(os.path.join(pathNumpySave, nombre_original), np.load(rutas_archivos[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "039ec07b-a9d7-492e-af77-e8d8e998d543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones del array combinado: (280,)\n"
     ]
    }
   ],
   "source": [
    "# Rutas de los archivos numpy generados por cada ordenador\n",
    "ruta_ordenador1 = \"progresoSeleccionActionable1.npy\"\n",
    "ruta_ordenador2 = \"progresoSeleccionActionable2.npy\"\n",
    "\n",
    "# Cargar los ssim_scores_promedio generados por cada ordenador\n",
    "ssim_scores_ordenador1 = np.load(ruta_ordenador1)\n",
    "ssim_scores_ordenador2 = np.load(ruta_ordenador2)\n",
    "\n",
    "# Combinar los ssim_scores_promedio\n",
    "ssim_scores_combinado = np.concatenate((ssim_scores_ordenador1, ssim_scores_ordenador2))\n",
    "\n",
    "# Verificar las dimensiones del array concatenado\n",
    "print(\"Dimensiones del array combinado:\", ssim_scores_combinado.shape)\n",
    "\n",
    "# Guardar el resultado combinado si es necesario\n",
    "np.save(\"progresoSeleccionActionable.npy\", ssim_scores_combinado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4bdbbb-839f-4765-a6ca-29db559c6feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actionable\n",
    "pathNumpy = \"E:/NumpysTotal/Actionable/\"\n",
    "pathNumpySave = \"E:/NumpysSeleccionadas/Actionable\"\n",
    "NumImagenes = 89  # Img Cancer Validation dataset\n",
    "\n",
    "# Lista para almacenar las rutas de los archivos .npy\n",
    "rutas_archivos = []\n",
    "for filename in os.listdir(pathNumpy):\n",
    "    if filename.endswith(\".npy\"):\n",
    "        rutas_archivos.append(os.path.join(pathNumpy, filename))\n",
    "\n",
    "# Mostrar la cantidad de archivos en rutas_archivos\n",
    "print(\"Cantidad de archivos .npy encontrados:\", len(rutas_archivos))\n",
    "\n",
    "archivo_progreso = \"progresoSeleccionBenign.npy\"\n",
    "archivo_progreso2 = \"progresoSeleccionBenign2.npy\"\n",
    "# Comprobar si existe un archivo de progreso guardado\n",
    "if os.path.exists(archivo_progreso):\n",
    "    print(\"Cargando progreso previo...\")\n",
    "    ssim_scores_promedio = np.load(archivo_progreso)\n",
    "else:\n",
    "    ssim_scores_promedio = np.empty((0,))\n",
    "\n",
    "ssim_scores_promedio2 = np.empty((len(rutas_archivos), 2), dtype=object)\n",
    "\n",
    "# Calcular SSIM entre cada archivo y todos los demás archivos\n",
    "for i, ruta_i in enumerate(rutas_archivos):\n",
    "    row_data = np.array([ssim_scores_promedio[i], ruta_i], dtype=object)\n",
    "    ssim_scores_promedio2[i] = row_data\n",
    "    print(ssim_scores_promedio2[i])\n",
    "    \n",
    "#np.save(archivo_progreso2, ssim_scores_promedio2)\n",
    "\n",
    "# Obtener los índices que ordenan ssim_scores_promedio por su primer atributo (promedio de SSIM)\n",
    "indices_ordenados = np.argsort(ssim_scores_promedio2[:, 0])\n",
    "\n",
    "# Ordenar ssim_scores_promedio en función de los índices obtenidos\n",
    "ssim_scores_promedio_ordenados = ssim_scores_promedio2[indices_ordenados]\n",
    "\n",
    "# Mostrar los resultados ordenados por pantalla\n",
    "for fila in ssim_scores_promedio_ordenados:\n",
    "    print(f\"Promedio de SSIM: {fila[0]}, Ruta del archivo: {fila[1]}\")\n",
    "\n",
    "# Seleccionar los primeros NumImagenes elementos de ssim_scores_promedio_ordenados\n",
    "ssim_scores_seleccionados = ssim_scores_promedio_ordenados[:NumImagenes]\n",
    "    \n",
    "\n",
    "# Guardar los archivos seleccionados con sus nombres originales\n",
    "for fila in ssim_scores_seleccionados:\n",
    "    print(f\"SSIM sleccionado: {fila[0]}, Ruta del archivo: {fila[1]}\")\n",
    "    ruta_archivo = fila[1]  # Obtener la ruta del archivo desde la segunda posición de la fila\n",
    "    nombre_original = os.path.basename(ruta_archivo)  # Obtener el nombre original del archivo\n",
    "    np.save(os.path.join(pathNumpySave, nombre_original), np.load(ruta_archivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a18a4c-6d20-4857-804b-03717c5d90a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cancer\n",
    "pathNumpy = \"E:/NumpysTotal/Cancer/\"\n",
    "pathNumpySave = \"E:/NumpysSeleccionadas/Cancer\"\n",
    "NumImagenes = 89  # Img Cancer Validation dataset\n",
    "\n",
    "# Lista para almacenar las rutas de los archivos .npy\n",
    "rutas_archivos = []\n",
    "for filename in os.listdir(pathNumpy):\n",
    "    if filename.endswith(\".npy\"):\n",
    "        rutas_archivos.append(os.path.join(pathNumpy, filename))\n",
    "\n",
    "# Mostrar la cantidad de archivos en rutas_archivos\n",
    "print(\"Cantidad de archivos .npy encontrados:\", len(rutas_archivos))\n",
    "\n",
    "archivo_progreso = \"progresoSeleccionCancer.npy\"\n",
    "# Comprobar si existe un archivo de progreso guardado\n",
    "if os.path.exists(archivo_progreso):\n",
    "    print(\"Cargando progreso previo...\")\n",
    "    ssim_scores_promedio = np.load(archivo_progreso)\n",
    "else:\n",
    "    ssim_scores_promedio = np.empty((0,))\n",
    "\n",
    "# Calcular SSIM entre cada archivo y todos los demás archivos\n",
    "for i, ruta_i in enumerate(rutas_archivos):\n",
    "    if i >= len(ssim_scores_promedio):  # Continuar desde donde se quedó\n",
    "        archivo_i = np.load(ruta_i)\n",
    "        scores_i = []\n",
    "        for j, ruta_j in enumerate(tqdm(rutas_archivos, desc=f\"Linea {i}\", unit=\"archivo\", leave=False)):\n",
    "            if i != j:  # Evitar comparar un archivo consigo mismo\n",
    "                archivo_j = np.load(ruta_j)\n",
    "                score_sum = 0\n",
    "                for k in range(10):  # Calcular SSIM para cada par de imágenes dentro de los archivos\n",
    "                    score, _ = ssim(archivo_i[k], archivo_j[k], full=True)\n",
    "                    score_sum += score\n",
    "                print(f\"Calculando: {i} - {j}  Total: {len(rutas_archivos)}\", end='\\r') \n",
    "                avg_score = score_sum / 10  # Promedio de las puntuaciones SSIM para las 10 imágenes\n",
    "                scores_i.append(avg_score)\n",
    "        ssim_scores_promedio.append((i, np.mean(scores_i)))\n",
    "        np.save(ssim_scores_promedio, ssim_scores_promedio)\n",
    "\n",
    "# Ordenar los scores promedio de menor a mayor\n",
    "ssim_scores_promedio.sort(key=lambda x: x[1])\n",
    "\n",
    "# Seleccionar los NumImagenes archivos menos similares al resto\n",
    "indices_seleccionados = [idx for idx, _ in ssim_scores_promedio[:NumImagenes]]\n",
    "\n",
    "# Guardar los archivos seleccionados con sus nombres originales\n",
    "for idx in indices_seleccionados:\n",
    "    nombre_original = os.path.basename(rutas_archivos[idx])  # Obtener el nombre original del archivo\n",
    "    np.save(os.path.join(pathNumpySave, nombre_original), np.load(rutas_archivos[idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8649ccd-2338-45ab-8233-98cba1f5de26",
   "metadata": {},
   "source": [
    "# DATA AUGMENTATION\n",
    "## Voltear y rotar Imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f1be4c0-9c95-4790-aa5e-7ed29a9d01d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flip_image_horizontal(image):\n",
    "    \"\"\"\n",
    "    Flips an image horizontally.\n",
    "    \"\"\"\n",
    "    flipped_image = cv2.flip(image, 1)\n",
    "    return flipped_image\n",
    "\n",
    "def flip_image_vertical(image):\n",
    "    \"\"\"\n",
    "    Flips an image vertically.\n",
    "    \"\"\"\n",
    "    flipped_image = cv2.flip(image, 0)\n",
    "    return flipped_image\n",
    "def rotate_image_90(image, times=1):\n",
    "    \"\"\"\n",
    "    Rotates an image by 90 degrees clockwise.\n",
    "    \"\"\"\n",
    "    rotated_image = image.copy()\n",
    "    for _ in range(times):\n",
    "        rotated_image = cv2.rotate(rotated_image, cv2.ROTATE_90_CLOCKWISE)\n",
    "    return rotated_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7c907f-6575-48f2-8449-1eab5060d908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo de uso:\n",
    "# Cargar el archivo .npy\n",
    "file_path = 'E:/NumpysTotal/Normal/DBT-S00034_DBT-P01371.npy'\n",
    "images = np.load(file_path)\n",
    "\n",
    "# Generar todas las combinaciones posibles de transformaciones\n",
    "transformations = [\n",
    "    (0, 0, 0),  # No transformation\n",
    "    (1, 0, 0),  # Rotación de 90 grados\n",
    "    (2, 0, 0),  # Rotación de 180 grados\n",
    "    (3, 0, 0),  # Rotación de 270 grados\n",
    "    (0, 1, 0),  # Volteo horizontal\n",
    "    (0, 0, 1),  # Volteo vertical\n",
    "    (1, 1, 0),  # Rotación de 90 grados + Volteo horizontal\n",
    "    (1, 0, 1),  # Rotación de 90 grados + Volteo vertical\n",
    "    (2, 1, 0),  # Rotación de 180 grados + Volteo horizontal\n",
    "    (2, 0, 1),  # Rotación de 180 grados + Volteo vertical\n",
    "    (3, 1, 0),  # Rotación de 270 grados + Volteo horizontal\n",
    "    (3, 0, 1),  # Rotación de 270 grados + Volteo vertical\n",
    "]\n",
    "\n",
    "# Aplicar las transformaciones a cada imagen y guardar en un nuevo archivo .npy\n",
    "for index, original_image in enumerate(images):\n",
    "    transformed_images = []\n",
    "    for rotation, horizontal_flip, vertical_flip in transformations:\n",
    "        transformed_image = original_image.copy()\n",
    "        transformed_image = rotate_image_90(transformed_image, times=rotation)\n",
    "        if horizontal_flip:\n",
    "            transformed_image = flip_image_horizontal(transformed_image)\n",
    "        if vertical_flip:\n",
    "            transformed_image = flip_image_vertical(transformed_image)\n",
    "        transformed_images.append(transformed_image)\n",
    "    \n",
    "        # Guardar las imágenes transformadas en un nuevo archivo .npy\n",
    "        output_file_path = f'resultados/transformada/imagen_{index}_{rotation}{horizontal_flip}{vertical_flip}.jpg'\n",
    "        cv2.imwrite(output_file_path, transformed_image)\n",
    "print(f'Imágenes transformadas de la imagen {index} guardadas en resultados/transformada/imagen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7be23e86-0e90-45c8-8f26-b29c98a1be14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculando: DBT-S05373_DBT-P00952.npy\r"
     ]
    }
   ],
   "source": [
    "# Normal:\n",
    "pathNumpy = \"E:/NumpysSeleccionadas/Normal\"\n",
    "pathNumpySave = \"E:/NumpysProcesadas/Normal\"\n",
    "\n",
    "# Generar todas las combinaciones posibles de transformaciones\n",
    "transformations = [\n",
    "    (0, 0, 0),  # No transformation\n",
    "    (1, 0, 0),  # Rotación de 90 grados\n",
    "    (2, 0, 0),  # Rotación de 180 grados\n",
    "    (3, 0, 0),  # Rotación de 270 grados\n",
    "    (0, 1, 0),  # Volteo horizontal\n",
    "    (0, 0, 1),  # Volteo vertical\n",
    "    (1, 1, 0),  # Rotación de 90 grados + Volteo horizontal\n",
    "    (1, 0, 1),  # Rotación de 90 grados + Volteo vertical\n",
    "    (2, 1, 0),  # Rotación de 180 grados + Volteo horizontal\n",
    "    (2, 0, 1),  # Rotación de 180 grados + Volteo vertical\n",
    "    (3, 1, 0),  # Rotación de 270 grados + Volteo horizontal\n",
    "    (3, 0, 1),  # Rotación de 270 grados + Volteo vertical\n",
    "]\n",
    "\n",
    "for filename in os.listdir(pathNumpy):\n",
    "    if filename.endswith(\".npy\"):\n",
    "        # Nombre del archivo original sin la extensión\n",
    "        original_filename = os.path.splitext(os.path.basename(filename))[0]\n",
    "        images = np.load(os.path.join(pathNumpy, filename))\n",
    "        # Aplicar las transformaciones a cada imagen y guardar en un nuevo archivo .npy\n",
    "        for rotation, horizontal_flip, vertical_flip in transformations:\n",
    "            output_file_path =os.path.join(pathNumpySave, f'{original_filename}transformed{rotation}{horizontal_flip}{vertical_flip}.npy') \n",
    "            if not os.path.exists(output_file_path):\n",
    "                transformed_images = []\n",
    "                for index, original_image in enumerate(images):\n",
    "                    transformed_image = original_image.copy()\n",
    "                    transformed_image = rotate_image_90(transformed_image, times=rotation)\n",
    "                    if horizontal_flip:\n",
    "                        transformed_image = flip_image_horizontal(transformed_image)\n",
    "                    if vertical_flip:\n",
    "                        transformed_image = flip_image_vertical(transformed_image)\n",
    "                    transformed_images.append(transformed_image)\n",
    "                # Guardar las imágenes transformadas en un nuevo archivo .npy\n",
    "\n",
    "                np.save(output_file_path, np.array(transformed_images))\n",
    "            \n",
    "    print(f\"Calculando: {filename}\", end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5c35a9-6127-4ac7-a048-7eba11f0b8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cancer:\n",
    "# Cancer\n",
    "pathNumpy = \"E:/NumpysSeleccionadas/Cancer\"\n",
    "pathNumpySave = \"E:/NumpysProcesadas/Cancer\"\n",
    "\n",
    "# Generar todas las combinaciones posibles de transformaciones\n",
    "transformations = [\n",
    "    (0, 0, 0),  # No transformation\n",
    "    (1, 0, 0),  # Rotación de 90 grados\n",
    "    (2, 0, 0),  # Rotación de 180 grados\n",
    "    (3, 0, 0),  # Rotación de 270 grados\n",
    "    (0, 1, 0),  # Volteo horizontal\n",
    "    (0, 0, 1),  # Volteo vertical\n",
    "    (1, 1, 0),  # Rotación de 90 grados + Volteo horizontal\n",
    "    (1, 0, 1),  # Rotación de 90 grados + Volteo vertical\n",
    "    (2, 1, 0),  # Rotación de 180 grados + Volteo horizontal\n",
    "    (2, 0, 1),  # Rotación de 180 grados + Volteo vertical\n",
    "    (3, 1, 0),  # Rotación de 270 grados + Volteo horizontal\n",
    "    (3, 0, 1),  # Rotación de 270 grados + Volteo vertical\n",
    "]\n",
    "\n",
    "for filename in os.listdir(pathNumpy):\n",
    "    if filename.endswith(\".npy\"):\n",
    "        # Nombre del archivo original sin la extensión\n",
    "        original_filename = os.path.splitext(os.path.basename(filename))[0]\n",
    "        images = np.load(os.path.join(pathNumpy, filename))\n",
    "        # Aplicar las transformaciones a cada imagen y guardar en un nuevo archivo .npy\n",
    "        for rotation, horizontal_flip, vertical_flip in transformations:\n",
    "            output_file_path =os.path.join(pathNumpySave, f'{original_filename}transformed{rotation}{horizontal_flip}{vertical_flip}.npy') \n",
    "            if not os.path.exists(output_file_path):\n",
    "                transformed_images = []\n",
    "                for index, original_image in enumerate(images):\n",
    "                    transformed_image = original_image.copy()\n",
    "                    transformed_image = rotate_image_90(transformed_image, times=rotation)\n",
    "                    if horizontal_flip:\n",
    "                        transformed_image = flip_image_horizontal(transformed_image)\n",
    "                    if vertical_flip:\n",
    "                        transformed_image = flip_image_vertical(transformed_image)\n",
    "                    transformed_images.append(transformed_image)\n",
    "                # Guardar las imágenes transformadas en un nuevo archivo .npy\n",
    "\n",
    "                np.save(output_file_path, np.array(transformed_images))\n",
    "            \n",
    "    print(f\"Calculando: {filename}\", end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6730dbc7-f58a-4a30-9d91-e094770f2107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actionable:\n",
    "pathNumpy = \"E:/NumpysSeleccionadas/Actionable\"\n",
    "pathNumpySave = \"E:/NumpysProcesadas/Actionable\"\n",
    "\n",
    "# Generar todas las combinaciones posibles de transformaciones\n",
    "transformations = [\n",
    "    (0, 0, 0),  # No transformation\n",
    "    (1, 0, 0),  # Rotación de 90 grados\n",
    "    (2, 0, 0),  # Rotación de 180 grados\n",
    "    (3, 0, 0),  # Rotación de 270 grados\n",
    "    (0, 1, 0),  # Volteo horizontal\n",
    "    (0, 0, 1),  # Volteo vertical\n",
    "    (1, 1, 0),  # Rotación de 90 grados + Volteo horizontal\n",
    "    (1, 0, 1),  # Rotación de 90 grados + Volteo vertical\n",
    "    (2, 1, 0),  # Rotación de 180 grados + Volteo horizontal\n",
    "    (2, 0, 1),  # Rotación de 180 grados + Volteo vertical\n",
    "    (3, 1, 0),  # Rotación de 270 grados + Volteo horizontal\n",
    "    (3, 0, 1),  # Rotación de 270 grados + Volteo vertical\n",
    "]\n",
    "\n",
    "for filename in os.listdir(pathNumpy):\n",
    "    if filename.endswith(\".npy\"):\n",
    "        # Nombre del archivo original sin la extensión\n",
    "        original_filename = os.path.splitext(os.path.basename(filename))[0]\n",
    "        images = np.load(os.path.join(pathNumpy, filename))\n",
    "        # Aplicar las transformaciones a cada imagen y guardar en un nuevo archivo .npy\n",
    "        for rotation, horizontal_flip, vertical_flip in transformations:\n",
    "            output_file_path =os.path.join(pathNumpySave, f'{original_filename}transformed{rotation}{horizontal_flip}{vertical_flip}.npy') \n",
    "            if not os.path.exists(output_file_path):\n",
    "                transformed_images = []\n",
    "                for index, original_image in enumerate(images):\n",
    "                    transformed_image = original_image.copy()\n",
    "                    transformed_image = rotate_image_90(transformed_image, times=rotation)\n",
    "                    if horizontal_flip:\n",
    "                        transformed_image = flip_image_horizontal(transformed_image)\n",
    "                    if vertical_flip:\n",
    "                        transformed_image = flip_image_vertical(transformed_image)\n",
    "                    transformed_images.append(transformed_image)\n",
    "                # Guardar las imágenes transformadas en un nuevo archivo .npy\n",
    "\n",
    "                np.save(output_file_path, np.array(transformed_images))\n",
    "            \n",
    "    print(f\"Calculando: {filename}\", end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f35b6ff-e9e8-43b9-b712-8a381e3df488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benign:\n",
    "pathNumpy = \"E:/NumpysSeleccionadas/Benign\"\n",
    "pathNumpySave = \"E:/NumpysProcesadas/Benign\"\n",
    "\n",
    "# Generar todas las combinaciones posibles de transformaciones\n",
    "transformations = [\n",
    "    (0, 0, 0),  # No transformation\n",
    "    (1, 0, 0),  # Rotación de 90 grados\n",
    "    (2, 0, 0),  # Rotación de 180 grados\n",
    "    (3, 0, 0),  # Rotación de 270 grados\n",
    "    (0, 1, 0),  # Volteo horizontal\n",
    "    (0, 0, 1),  # Volteo vertical\n",
    "    (1, 1, 0),  # Rotación de 90 grados + Volteo horizontal\n",
    "    (1, 0, 1),  # Rotación de 90 grados + Volteo vertical\n",
    "    (2, 1, 0),  # Rotación de 180 grados + Volteo horizontal\n",
    "    (2, 0, 1),  # Rotación de 180 grados + Volteo vertical\n",
    "    (3, 1, 0),  # Rotación de 270 grados + Volteo horizontal\n",
    "    (3, 0, 1),  # Rotación de 270 grados + Volteo vertical\n",
    "]\n",
    "\n",
    "for filename in os.listdir(pathNumpy):\n",
    "    if filename.endswith(\".npy\"):\n",
    "        # Nombre del archivo original sin la extensión\n",
    "        original_filename = os.path.splitext(os.path.basename(filename))[0]\n",
    "        images = np.load(os.path.join(pathNumpy, filename))\n",
    "        # Aplicar las transformaciones a cada imagen y guardar en un nuevo archivo .npy\n",
    "        for rotation, horizontal_flip, vertical_flip in transformations:\n",
    "            output_file_path =os.path.join(pathNumpySave, f'{original_filename}transformed{rotation}{horizontal_flip}{vertical_flip}.npy') \n",
    "            if not os.path.exists(output_file_path):\n",
    "                transformed_images = []\n",
    "                for index, original_image in enumerate(images):\n",
    "                    transformed_image = original_image.copy()\n",
    "                    transformed_image = rotate_image_90(transformed_image, times=rotation)\n",
    "                    if horizontal_flip:\n",
    "                        transformed_image = flip_image_horizontal(transformed_image)\n",
    "                    if vertical_flip:\n",
    "                        transformed_image = flip_image_vertical(transformed_image)\n",
    "                    transformed_images.append(transformed_image)\n",
    "                # Guardar las imágenes transformadas en un nuevo archivo .npy\n",
    "\n",
    "                np.save(output_file_path, np.array(transformed_images))\n",
    "            \n",
    "    print(f\"Calculando: {filename}\", end='\\r')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63c1bbf-1216-4db7-94ad-18e6f5828216",
   "metadata": {},
   "source": [
    "# Separar en Training, Validation y Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56b99dd7-a7af-4756-8bed-0b3c47122584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para copiar archivos a los directorios correspondientes según el prefijo\n",
    "def copy_files_by_prefix(prefixes, source_dir, output_dir):\n",
    "    for prefix in prefixes:\n",
    "        # Obtener los archivos correspondientes al prefijo\n",
    "        prefix_files = [file for file in os.listdir(source_dir) if file.startswith(prefix)]\n",
    "        \n",
    "        # Copiar los archivos a los directorios correspondientes\n",
    "        for file in prefix_files:\n",
    "            source_file = os.path.join(source_dir, file)\n",
    "            if prefix in training_prefixes:\n",
    "                destination = os.path.join(output_dir, \"Training\", file)\n",
    "            elif prefix in validation_prefixes:\n",
    "                destination = os.path.join(output_dir, \"Validation\", file)\n",
    "            else:\n",
    "                destination = os.path.join(output_dir, \"Test\", file)\n",
    "            shutil.copy(source_file, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26328875-4b6b-46cf-94eb-4f9b0267f405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad total de prefijos: 89\n",
      "Cantidad de prefijos para Training: 58\n",
      "Cantidad de prefijos para Validation: 17\n",
      "Cantidad de prefijos para Test: 14\n",
      "Training completado.\n",
      "Validation completado.\n",
      "Test completado.\n",
      "Proceso completado.\n"
     ]
    }
   ],
   "source": [
    "# Benign\n",
    "# Directorios de entrada y salida\n",
    "input_directory = \"E:/NumpysProcesadas/Benign\"\n",
    "output_directory = \"E:/NumpysFinales/Benign\"\n",
    "\n",
    "# Crear directorios de Training, Validation y Test si no existen\n",
    "for division in [\"Training\", \"Validation\", \"Test\"]:\n",
    "    division_dir = os.path.join(output_directory, division)\n",
    "    if not os.path.exists(division_dir):\n",
    "        os.makedirs(division_dir)\n",
    "\n",
    "# Obtener la lista de archivos npy en el directorio de entrada\n",
    "npy_files = [f for f in os.listdir(input_directory) if f.endswith('.npy')]\n",
    "\n",
    "# Crear una lista para almacenar los prefijos de las imágenes\n",
    "image_prefixes = []\n",
    "for npy_file in npy_files:\n",
    "    file_name = os.path.splitext(npy_file)[0]  # Obtener el nombre del archivo sin la extensión .npy\n",
    "    prefix = \"_\".join(file_name.split('_')[:2])  # Obtener el prefijo del nombre completo\n",
    "    if prefix not in image_prefixes:\n",
    "        image_prefixes.append(prefix)\n",
    "\n",
    "# Mostrar los prefijos guardados por pantalla\n",
    "# print(\"Prefijos de las imágenes:\")\n",
    "# for prefix in image_prefixes:\n",
    "#     print(prefix)\n",
    "\n",
    "# Mostrar la cantidad total de prefijos\n",
    "total_prefixes = len(image_prefixes)\n",
    "print(\"Cantidad total de prefijos:\", total_prefixes)\n",
    "\n",
    "# Determinar la cantidad de prefijos para cada conjunto (Training, Validation, Test)\n",
    "num_prefixes = len(image_prefixes)\n",
    "num_training_prefixes = 58 # int(0.6 * num_prefixes)  # 60% para Training\n",
    "num_validation_prefixes = 17 # int(0.2 * num_prefixes)  # 20% para Validation\n",
    "num_test_prefixes = num_prefixes - num_training_prefixes - num_validation_prefixes  # El resto para Test\n",
    "\n",
    "# Imprimir la cantidad de prefijos para cada conjunto\n",
    "print(\"Cantidad de prefijos para Training:\", num_training_prefixes)\n",
    "print(\"Cantidad de prefijos para Validation:\", num_validation_prefixes)\n",
    "print(\"Cantidad de prefijos para Test:\", num_test_prefixes)\n",
    "\n",
    "# Seleccionar aleatoriamente los prefijos para cada conjunto\n",
    "random.shuffle(image_prefixes)\n",
    "training_prefixes = image_prefixes[:num_training_prefixes]\n",
    "validation_prefixes = image_prefixes[num_training_prefixes:num_training_prefixes + num_validation_prefixes]\n",
    "test_prefixes = image_prefixes[num_training_prefixes + num_validation_prefixes:]\n",
    "\n",
    "# Mostrar los prefijos seleccionados para cada conjunto por pantalla\n",
    "# print(\"Prefijos seleccionados para Training:\")\n",
    "# for prefix in training_prefixes:\n",
    "#     print(prefix)\n",
    "# print(\"Prefijos seleccionados para Validation:\")\n",
    "# for prefix in validation_prefixes:\n",
    "#     print(prefix)\n",
    "# print(\"Prefijos seleccionados para Test:\")\n",
    "# for prefix in test_prefixes:\n",
    "#     print(prefix)\n",
    "\n",
    "# Copiar archivos por prefijo para Training, Validation y Test\n",
    "copy_files_by_prefix(training_prefixes, input_directory, output_directory)\n",
    "print(\"Training completado.\")\n",
    "copy_files_by_prefix(validation_prefixes, input_directory, output_directory)\n",
    "print(\"Validation completado.\")\n",
    "copy_files_by_prefix(test_prefixes, input_directory, output_directory)\n",
    "print(\"Test completado.\")\n",
    "\n",
    "print(\"Proceso completado.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "babe698e-487f-4e2e-959f-73ad1a4e8cbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad total de prefijos: 89\n",
      "Cantidad de prefijos para Training: 58\n",
      "Cantidad de prefijos para Validation: 17\n",
      "Cantidad de prefijos para Test: 14\n",
      "Training completado.\n",
      "Validation completado.\n",
      "Test completado.\n",
      "Proceso completado.\n"
     ]
    }
   ],
   "source": [
    "# Normal\n",
    "# Directorios de entrada y salida\n",
    "input_directory = \"E:/NumpysProcesadas/Normal\"\n",
    "output_directory = \"E:/NumpysFinales/Normal\"\n",
    "\n",
    "# Crear directorios de Training, Validation y Test si no existen\n",
    "for division in [\"Training\", \"Validation\", \"Test\"]:\n",
    "    division_dir = os.path.join(output_directory, division)\n",
    "    if not os.path.exists(division_dir):\n",
    "        os.makedirs(division_dir)\n",
    "\n",
    "# Obtener la lista de archivos npy en el directorio de entrada\n",
    "npy_files = [f for f in os.listdir(input_directory) if f.endswith('.npy')]\n",
    "\n",
    "# Crear una lista para almacenar los prefijos de las imágenes\n",
    "image_prefixes = []\n",
    "for npy_file in npy_files:\n",
    "    file_name = os.path.splitext(npy_file)[0]  # Obtener el nombre del archivo sin la extensión .npy\n",
    "    prefix = \"_\".join(file_name.split('_')[:1])  # Obtener el prefijo del nombre completo\n",
    "    if prefix not in image_prefixes:\n",
    "        image_prefixes.append(prefix)\n",
    "\n",
    "# Mostrar los prefijos guardados por pantalla\n",
    "# print(\"Prefijos de las imágenes:\")\n",
    "# for prefix in image_prefixes:\n",
    "#     print(prefix)\n",
    "\n",
    "# Mostrar la cantidad total de prefijos\n",
    "total_prefixes = len(image_prefixes)\n",
    "print(\"Cantidad total de prefijos:\", total_prefixes)\n",
    "\n",
    "# Determinar la cantidad de prefijos para cada conjunto (Training, Validation, Test)\n",
    "num_prefixes = len(image_prefixes)\n",
    "num_training_prefixes = 58 # int(0.6 * num_prefixes)  # 60% para Training\n",
    "num_validation_prefixes = 17 # int(0.2 * num_prefixes)  # 20% para Validation\n",
    "num_test_prefixes = num_prefixes - num_training_prefixes - num_validation_prefixes  # El resto para Test\n",
    "\n",
    "# Imprimir la cantidad de prefijos para cada conjunto\n",
    "print(\"Cantidad de prefijos para Training:\", num_training_prefixes)\n",
    "print(\"Cantidad de prefijos para Validation:\", num_validation_prefixes)\n",
    "print(\"Cantidad de prefijos para Test:\", num_test_prefixes)\n",
    "\n",
    "# Seleccionar aleatoriamente los prefijos para cada conjunto\n",
    "random.shuffle(image_prefixes)\n",
    "training_prefixes = image_prefixes[:num_training_prefixes]\n",
    "validation_prefixes = image_prefixes[num_training_prefixes:num_training_prefixes + num_validation_prefixes]\n",
    "test_prefixes = image_prefixes[num_training_prefixes + num_validation_prefixes:]\n",
    "\n",
    "# Mostrar los prefijos seleccionados para cada conjunto por pantalla\n",
    "# print(\"Prefijos seleccionados para Training:\")\n",
    "# for prefix in training_prefixes:\n",
    "#     print(prefix)\n",
    "# print(\"Prefijos seleccionados para Validation:\")\n",
    "# for prefix in validation_prefixes:\n",
    "#     print(prefix)\n",
    "# print(\"Prefijos seleccionados para Test:\")\n",
    "# for prefix in test_prefixes:\n",
    "#     print(prefix)\n",
    "\n",
    "# Copiar archivos por prefijo para Training, Validation y Test\n",
    "copy_files_by_prefix(training_prefixes, input_directory, output_directory)\n",
    "print(\"Training completado.\")\n",
    "copy_files_by_prefix(validation_prefixes, input_directory, output_directory)\n",
    "print(\"Validation completado.\")\n",
    "copy_files_by_prefix(test_prefixes, input_directory, output_directory)\n",
    "print(\"Test completado.\")\n",
    "\n",
    "print(\"Proceso completado.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "296c7c94-a000-4828-ba64-9c15470ee4d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad total de prefijos: 89\n",
      "Cantidad de prefijos para Training: 58\n",
      "Cantidad de prefijos para Validation: 17\n",
      "Cantidad de prefijos para Test: 14\n",
      "Training completado.\n",
      "Validation completado.\n",
      "Test completado.\n",
      "Proceso completado.\n"
     ]
    }
   ],
   "source": [
    "# Cancer\n",
    "# Directorios de entrada y salida\n",
    "input_directory = \"E:/NumpysProcesadas/Cancer\"\n",
    "output_directory = \"E:/NumpysFinales/Cancer\"\n",
    "\n",
    "# Crear directorios de Training, Validation y Test si no existen\n",
    "for division in [\"Training\", \"Validation\", \"Test\"]:\n",
    "    division_dir = os.path.join(output_directory, division)\n",
    "    if not os.path.exists(division_dir):\n",
    "        os.makedirs(division_dir)\n",
    "\n",
    "# Obtener la lista de archivos npy en el directorio de entrada\n",
    "npy_files = [f for f in os.listdir(input_directory) if f.endswith('.npy')]\n",
    "\n",
    "# Crear una lista para almacenar los prefijos de las imágenes\n",
    "image_prefixes = []\n",
    "for npy_file in npy_files:\n",
    "    file_name = os.path.splitext(npy_file)[0]  # Obtener el nombre del archivo sin la extensión .npy\n",
    "    prefix = \"_\".join(file_name.split('_')[:2])  # Obtener el prefijo del nombre completo\n",
    "    if prefix not in image_prefixes:\n",
    "        image_prefixes.append(prefix)\n",
    "\n",
    "# Mostrar los prefijos guardados por pantalla\n",
    "# print(\"Prefijos de las imágenes:\")\n",
    "# for prefix in image_prefixes:\n",
    "#     print(prefix)\n",
    "\n",
    "# Mostrar la cantidad total de prefijos\n",
    "total_prefixes = len(image_prefixes)\n",
    "print(\"Cantidad total de prefijos:\", total_prefixes)\n",
    "\n",
    "# Definir los tamaños deseados para cada conjunto\n",
    "num_training_samples = 700\n",
    "num_validation_samples = 150\n",
    "\n",
    "# Determinar la cantidad de prefijos para cada conjunto (Training, Validation, Test)\n",
    "num_prefixes = len(image_prefixes)\n",
    "num_training_prefixes = 58 # int(0.6 * num_prefixes)  # 60% para Training\n",
    "num_validation_prefixes = 17 # int(0.2 * num_prefixes)  # 20% para Validation\n",
    "num_test_prefixes = num_prefixes - num_training_prefixes - num_validation_prefixes  # El resto para Test\n",
    "\n",
    "# Imprimir la cantidad de prefijos para cada conjunto\n",
    "print(\"Cantidad de prefijos para Training:\", num_training_prefixes)\n",
    "print(\"Cantidad de prefijos para Validation:\", num_validation_prefixes)\n",
    "print(\"Cantidad de prefijos para Test:\", num_test_prefixes)\n",
    "\n",
    "# Seleccionar aleatoriamente los prefijos para cada conjunto\n",
    "random.shuffle(image_prefixes)\n",
    "training_prefixes = image_prefixes[:num_training_prefixes]\n",
    "validation_prefixes = image_prefixes[num_training_prefixes:num_training_prefixes + num_validation_prefixes]\n",
    "test_prefixes = image_prefixes[num_training_prefixes + num_validation_prefixes:]\n",
    "\n",
    "# Mostrar los prefijos seleccionados para cada conjunto por pantalla\n",
    "# print(\"Prefijos seleccionados para Training:\")\n",
    "# for prefix in training_prefixes:\n",
    "#     print(prefix)\n",
    "# print(\"Prefijos seleccionados para Validation:\")\n",
    "# for prefix in validation_prefixes:\n",
    "#     print(prefix)\n",
    "# print(\"Prefijos seleccionados para Test:\")\n",
    "# for prefix in test_prefixes:\n",
    "#     print(prefix)\n",
    "\n",
    "# Copiar archivos por prefijo para Training, Validation y Test\n",
    "copy_files_by_prefix(training_prefixes, input_directory, output_directory)\n",
    "print(\"Training completado.\")\n",
    "copy_files_by_prefix(validation_prefixes, input_directory, output_directory)\n",
    "print(\"Validation completado.\")\n",
    "copy_files_by_prefix(test_prefixes, input_directory, output_directory)\n",
    "print(\"Test completado.\")\n",
    "\n",
    "print(\"Proceso completado.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98b6a75-d75c-4750-965e-2e7655f0daed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actionable\n",
    "# Directorios de entrada y salida\n",
    "input_directory = \"E:/NumpysProcesadas/Actionable\"\n",
    "output_directory = \"E:/NumpysFinales/Actionable\"\n",
    "\n",
    "# Crear directorios de Training, Validation y Test si no existen\n",
    "for division in [\"Training\", \"Validation\", \"Test\"]:\n",
    "    division_dir = os.path.join(output_directory, division)\n",
    "    if not os.path.exists(division_dir):\n",
    "        os.makedirs(division_dir)\n",
    "\n",
    "# Obtener la lista de archivos npy en el directorio de entrada\n",
    "npy_files = [f for f in os.listdir(input_directory) if f.endswith('.npy')]\n",
    "\n",
    "# Crear una lista para almacenar los prefijos de las imágenes\n",
    "image_prefixes = []\n",
    "for npy_file in npy_files:\n",
    "    file_name = os.path.splitext(npy_file)[0]  # Obtener el nombre del archivo sin la extensión .npy\n",
    "    prefix = \"_\".join(file_name.split('_')[:2])  # Obtener el prefijo del nombre completo\n",
    "    if prefix not in image_prefixes:\n",
    "        image_prefixes.append(prefix)\n",
    "\n",
    "# Mostrar los prefijos guardados por pantalla\n",
    "# print(\"Prefijos de las imágenes:\")\n",
    "# for prefix in image_prefixes:\n",
    "#     print(prefix)\n",
    "\n",
    "# Mostrar la cantidad total de prefijos\n",
    "total_prefixes = len(image_prefixes)\n",
    "print(\"Cantidad total de prefijos:\", total_prefixes)\n",
    "\n",
    "# Definir los tamaños deseados para cada conjunto\n",
    "num_training_samples = 700\n",
    "num_validation_samples = 150\n",
    "\n",
    "# Determinar la cantidad de prefijos para cada conjunto (Training, Validation, Test)\n",
    "num_prefixes = len(image_prefixes)\n",
    "num_training_prefixes = 58 # int(0.6 * num_prefixes)  # 60% para Training\n",
    "num_validation_prefixes = 17 # int(0.2 * num_prefixes)  # 20% para Validation\n",
    "num_test_prefixes = num_prefixes - num_training_prefixes - num_validation_prefixes  # El resto para Test\n",
    "\n",
    "# Imprimir la cantidad de prefijos para cada conjunto\n",
    "print(\"Cantidad de prefijos para Training:\", num_training_prefixes)\n",
    "print(\"Cantidad de prefijos para Validation:\", num_validation_prefixes)\n",
    "print(\"Cantidad de prefijos para Test:\", num_test_prefixes)\n",
    "\n",
    "# Seleccionar aleatoriamente los prefijos para cada conjunto\n",
    "random.shuffle(image_prefixes)\n",
    "training_prefixes = image_prefixes[:num_training_prefixes]\n",
    "validation_prefixes = image_prefixes[num_training_prefixes:num_training_prefixes + num_validation_prefixes]\n",
    "test_prefixes = image_prefixes[num_training_prefixes + num_validation_prefixes:]\n",
    "\n",
    "# Mostrar los prefijos seleccionados para cada conjunto por pantalla\n",
    "# print(\"Prefijos seleccionados para Training:\")\n",
    "# for prefix in training_prefixes:\n",
    "#     print(prefix)\n",
    "# print(\"Prefijos seleccionados para Validation:\")\n",
    "# for prefix in validation_prefixes:\n",
    "#     print(prefix)\n",
    "# print(\"Prefijos seleccionados para Test:\")\n",
    "# for prefix in test_prefixes:\n",
    "#     print(prefix)\n",
    "\n",
    "# Copiar archivos por prefijo para Training, Validation y Test\n",
    "copy_files_by_prefix(training_prefixes, input_directory, output_directory)\n",
    "print(\"Training completado.\")\n",
    "copy_files_by_prefix(validation_prefixes, input_directory, output_directory)\n",
    "print(\"Validation completado.\")\n",
    "copy_files_by_prefix(test_prefixes, input_directory, output_directory)\n",
    "print(\"Test completado.\")\n",
    "\n",
    "print(\"Proceso completado.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e51d2e0-5da0-404d-99cc-4b15737d387b",
   "metadata": {},
   "source": [
    "# Probar validación cruzada"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
